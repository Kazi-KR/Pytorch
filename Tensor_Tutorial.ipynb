{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d8e1001-d8a4-4338-b6e8-fbf65a8a6254",
   "metadata": {},
   "source": [
    "### Introduction to Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6941858a-6799-4dbb-b8c4-5f97e5ca7e79",
   "metadata": {},
   "source": [
    "Lets talk about tensor. What is a `tensor`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e5311a-cae7-467e-b40e-d09b498e4dfe",
   "metadata": {},
   "source": [
    "Typically, machine learning models are fed a large number of data to train. However, these datas need to converted into numbers so that different ml algorithms can be applied on them. We convert different datas into `tensors` which are basically multidimensional array/matrix or we can say that tensors are numerical representation of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ec9f85c-cc36-4900-9b60-8eae81c58343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c671d48-82b6-47dc-85d8-03f4747bddd0",
   "metadata": {},
   "source": [
    "Pytorch has a dedicated documentation page on [tensors](https://pytorch.org/docs/stable/tensors.html). To learn more on tensors you can visit the official page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ab4a521-033f-452e-b49e-d108a0e1d2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar=torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488e5a35-4761-4667-aaef-6aa665869029",
   "metadata": {},
   "source": [
    "To create a tensor we call the `torch.tensor()` and pass the value as a parameter. Above we have created a scalar which is of type `torch.tensor` and with `ndim` we can get the dimension of the scalar. As scalar has a single value, hence its dimension is zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36c37685-68b4-4f1b-a685-e127523edf38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bb256a-62c7-4cd2-8893-e4769090e0ff",
   "metadata": {},
   "source": [
    "Let's create a vector/1-d array now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad631efa-bd67-4fe4-a4ef-23b415424ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector=torch.tensor([2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "299a0b3f-63b5-49cd-be2a-39e5e6f5d7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8dda5fa-218e-49b5-bfb9-c5bed872853c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb2cfa1-3b8c-4192-a058-8aab2838845e",
   "metadata": {},
   "source": [
    "Here, as we created a vector, the dimnesion is 1 and `size()` returns the items in the vector. Now that we have seen vectors lets see some matrix/2-d array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e60a4b80-b50f-4f19-a65a-427e36f5767d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix=torch.tensor([[2,3],[5,6]])\n",
    "Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82aa51be-e7db-4d57-bbf8-109770246202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8566bc18-1733-4b92-86ab-59bb350911da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0daf6d7-ab6b-488c-b33e-aa0ead15dabb",
   "metadata": {},
   "source": [
    "Using `shape` we can see the size of the `MATRIX` is of [2,2] because `MATRIX` is two elements deep and two elements wide. Lets dive into `Tensors` now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "705d37fe-7ba7-4acd-99eb-ee45ec3bc21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [7, 8, 1],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor = torch.tensor([[[1, 2, 3],\n",
    "                        [7, 8, 1],\n",
    "                        [2, 4, 5]]])\n",
    "Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4682ff1f-ea2f-4a68-b68c-c889c31f02c9",
   "metadata": {},
   "source": [
    "Wooo... We just created a `Tensor`. Lets check out the dimension...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29e3df7e-cfb6-4fc9-9033-60952625c580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986a96af-c66d-489c-9c9f-e3a8053431cf",
   "metadata": {},
   "source": [
    "Lets count the number of brackets at the beginning in the `Tensor`. Can you guess something?? The dimension is 3 as the brackets we counted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cf846d3-f698-463c-b0a0-b6b18665b8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3d40cd-0cca-4e11-8f3c-b01f68d57ebc",
   "metadata": {},
   "source": [
    "What is with that shape [1,3,3]? Lets think.... Wait, it is counted from the outer brackets to inside. The outer bracket has one element after that the inner bracket has three element [1,2,3] [7,8,1] [2,4,5] and the each element has three more elements 1,2,3. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99832e06-6fc1-4716-9c3f-4cae15dfac54",
   "metadata": {},
   "source": [
    "### Creating Tensor using random numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47317cc-771e-4da8-976a-92862b572fad",
   "metadata": {},
   "source": [
    "Using `rand()` function we can create a random tensor with the expected size as a parameter. Here, we have set the size=(3,4) and got a Tensor back with random numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15a108da-a107-4ccf-8b3c-1d035e80350f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2959, 0.6114, 0.2762, 0.2221],\n",
       "        [0.5545, 0.3278, 0.0836, 0.9979],\n",
       "        [0.3212, 0.9734, 0.7829, 0.5209]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random=torch.rand(size=(3,4))\n",
    "random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58e8bb73-e737-4b4f-bc23-67b78c58dd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d936a7e0-e625-4eb9-a91a-c98372a61499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.9606, 0.2998, 0.2386],\n",
       "          [0.6171, 0.6288, 0.8362],\n",
       "          [0.3800, 0.7077, 0.8832]]]),\n",
       " 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor=torch.rand(size=(1,3,3))\n",
    "random_tensor, random_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de852ca7-e103-4a87-9b05-f55f79dd6b8c",
   "metadata": {},
   "source": [
    "We can create tensors with zeros and ones if needed as we might need some dummy tensors for different purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "608c4f4a-8b1a-4b62-af73-e5906a55373d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_with_ones=torch.ones((3,2))\n",
    "tensor_with_ones, tensor_with_ones.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1fdf46b5-698b-4ea6-809f-ad18ce0a2d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_with_zeros=torch.zeros((3,4))\n",
    "tensor_with_zeros, tensor_with_zeros.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9435d22a-d1a4-4513-a0e1-ba49e2361be7",
   "metadata": {},
   "source": [
    "### Informations of Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e2ba6e-f336-4955-b9e0-d9890657a3a3",
   "metadata": {},
   "source": [
    "Tensor has different `datatype`. In the official documentation you can checkout different type of datatypes in PyTorch. While working in machine learning the most used type is `torch.float` or `torch.float32`. Tensors can be an integers, floats and boolean type. There are different bit implementation of all. Floats can be 8, 16, 32 or 64 bit. The higher the bit the more precision we get. So higher bit tensor calculation gives us better result with the trade-off being computation cost where using a lower precision gives faster answer but will be less accurate. Also, sometimes we might see `tensor.cuda` mentioned in different places that means GPU will handle the calculation of that tensor. For macbooks its `mps`.  So there can be device specific tensors. Noramlly, tensors are created and device is set to cpu and to use that in GPU we need to specifically set instruction for that tensor being used in GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f011de6-7df1-4936-85dd-8e666706c962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_t1=torch.arange(0,10,1.0) # we can use arange(start,stop,step) to generate a tensor\n",
    "tensor_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e743da3f-4104-49aa-add6-5c4252b3cd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_t1.dtype, tensor_t1.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76428705-ac2c-462e-b560-3102f9e900d2",
   "metadata": {},
   "source": [
    "**It seems our created tensor is running in cpu, lets change the device to \"mps\" as I am running it on macbook.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3536f3b7-e5d7-4128-90f0-b393854b0575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=\"mps\" if torch.backends.mps.is_available() else \"cpu\" #change \"mps\" into cuda if you are using cuda enabled gpu\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8613db5-7725-42c3-bea4-30ae60e7b166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, device(type='mps', index=0))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_t2_gpu=tensor_t1.to(device)\n",
    "tensor_t2_gpu.dtype, tensor_t2_gpu.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cecf60-3c59-4783-9732-2a8e79e17102",
   "metadata": {},
   "source": [
    "Now that we have converted the device type of our tensor to gpu , how do we get back to cpu?? Lets try to convert the device type gpu to  cpu in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43a402fe-1fa5-4395-a0d3-aa8815590e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_t2_cpu=tensor_t2_gpu.cpu().numpy()\n",
    "tensor_t2_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df63311-8d91-4ffb-9ebc-98e070231a47",
   "metadata": {},
   "source": [
    "using `cpu()` we can change the device from gpu to cpu . The above returns a copy of the GPU tensor in CPU memory so the original tensor is still on GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfe1865-59e6-42f2-8b21-402fd70c95e0",
   "metadata": {},
   "source": [
    "**Changing tensor datatype**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa6aadf-8fac-4744-9f0d-48412e1b30b6",
   "metadata": {},
   "source": [
    "Sometimes there might be a scenario when you need to change tensor datatype into other type for different purpose. We can use `type()` to convert one tensor to another datatype and pass the desired tensor type as a parameter.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c5c690d-866e-4c4e-9093-f644bea20c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0000, 1.1000, 2.2000, 3.3000, 4.4000, 5.5000, 6.6000, 7.7000, 8.8000,\n",
       "         9.9000]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_t3=torch.arange(0,10,1.1)\n",
    "tensor_t3, tensor_t3.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6897c267-d8d1-4fa6-8853-3cf6bfb07cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int16)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_t4=tensor_t3.type(torch.int16)\n",
    "tensor_t4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c4b8b6-2da3-4bdf-a4d1-98531af1305e",
   "metadata": {},
   "source": [
    "### Reshaping, Squeezing and Unsqueezing of TENSORS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a87067f-3978-4a19-ab5a-49648a1d3897",
   "metadata": {},
   "source": [
    "Sometimes we might need to change the dimension of the tensors without changing the elements of the tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8f26c0c-ab0e-4416-b5e7-abe499ce2682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 1.0300, 2.0600, 3.0900, 4.1200, 5.1500, 6.1800, 7.2100, 8.2400,\n",
       "        9.2700])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_t5=torch.arange(0,10,1.03)\n",
    "tensor_t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4c4925a-f9fe-43f3-9d18-01de0ced3f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_t5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62d70ebc-8511-4bb4-ab71-fde5a59ec3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000, 1.0300, 2.0600, 3.0900, 4.1200, 5.1500, 6.1800, 7.2100, 8.2400,\n",
       "          9.2700]]),\n",
       " torch.Size([1, 10]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_t5=tensor_t5.reshape(1,10)\n",
    "tensor_t5, tensor_t5.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd320d9-43ea-48c5-85bf-07fbc3c83450",
   "metadata": {},
   "source": [
    "We can convert a tensor into 1-d using `squeeze()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "869afead-7e60-465c-97f3-89d74c819657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor vlaues: tensor([[0.0000, 1.0300, 2.0600, 3.0900, 4.1200, 5.1500, 6.1800, 7.2100, 8.2400,\n",
      "         9.2700]])\n",
      "Tensor previous shape, torch.Size([1, 10])\n",
      "======================================\n",
      "After squeezing Tensor values: tensor([0.0000, 1.0300, 2.0600, 3.0900, 4.1200, 5.1500, 6.1800, 7.2100, 8.2400,\n",
      "        9.2700])\n",
      "After squeezing Tensor shape: torch.Size([10]) \n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensor vlaues: {tensor_t5}\")\n",
    "print(f\"Tensor previous shape, {tensor_t5.shape}\")\n",
    "print(\"======================================\")\n",
    "print(f\"After squeezing Tensor values: {tensor_t5.squeeze()}\")\n",
    "print(f\"After squeezing Tensor shape: {tensor_t5.squeeze().shape} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "580d1340-1bf4-4dbf-aafd-3456a1ebbea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 1.0300, 2.0600, 3.0900, 4.1200, 5.1500, 6.1800, 7.2100, 8.2400,\n",
       "        9.2700])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_t5=tensor_t5.squeeze()\n",
    "tensor_t5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51fe046-366d-4b0e-b7ce-464c3d0a656f",
   "metadata": {},
   "source": [
    "We can add an extra dimension using `unsqueeze()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "206161e9-1fe0-46f5-8d89-abc25ea095d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 1.0300, 2.0600, 3.0900, 4.1200, 5.1500, 6.1800, 7.2100, 8.2400,\n",
       "         9.2700]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_t5.unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89ef1fa-02c3-45f7-a2a5-313c387f4f25",
   "metadata": {},
   "source": [
    "Here I have tried to show most common used tensor methods. There are lots of things that are not covered over here. If needed just visit the official pytorch documentation for more on tensors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
